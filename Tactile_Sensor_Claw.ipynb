{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IkqlteS5WSom",
        "24fGXCv4qSkQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.初始化环境\n",
        "只考虑Colab环境, 不考虑本地NoteBook。\n",
        "\n",
        "## 1.1 显卡驱动检查\n",
        "查看CUDA版本以供PyTorch安装使用。\n",
        "\n",
        "如果执行失败, 检查运行时中是否正确选择GPU。\n",
        "\n",
        "## 1.2 PyTorch安装\n",
        "[PyTorch官网](https://pytorch.org/)\n",
        "\n",
        "暂时配置: Stable、Linux、Pip、Python、CUDA 11.3\n",
        "\n",
        "使用官网给出的命令安装\n",
        "\n",
        "## 1.3 挂载Google Drive\n",
        "1. 不更改工作目录, 网络I/O通讯太慢。\n",
        "2. 训练集直接拷贝到Colab本地。\n",
        "3. **断点路径一定在Google Drive而不是Colab本地。**\n",
        "\n",
        "以上问题在Config类中配置。"
      ],
      "metadata": {
        "id": "IkqlteS5WSom",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qWOjU9qT3DO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc631b7-a3fc-4a06-a303-4151ee229e44",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep  6 16:57:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# 1.1显卡驱动检查\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 PyTorch安装\n",
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "XMLuWLLceZhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f33e890-63fe-4489-fc7e-ad25a10e98c1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 1.3 挂载Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2tl7cXhqSkO",
        "outputId": "b7f49f95-d932-4849-a508-8377a475be92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "from torch.nn import Module, LSTM, Linear, BatchNorm1d\n",
        "from torch.utils.data import DataLoader, TensorDataset  # 常用工具区关于data区\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision.models\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "0Yq4sTGzqSkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 从网络硬盘中加载代码"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7CdEye7_qSkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 路径的设置"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "24fGXCv4qSkQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "GOOGLE_DRIVE_PATH = \"/content/drive/MyDrive\"\n",
        "PROJECT_NAME = \"fruit\"\n",
        "PROJECT_PATH = os.path.join(GOOGLE_DRIVE_PATH, PROJECT_NAME)\n",
        "\n",
        "# - fruit\n",
        "# +-- data\n",
        "# +-- label\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "I9VS7WlTqSkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 load_from_drive及其配套函数"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "yJVlsQbOqSkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2._\n",
        "这个标题用于缩进"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cMHfDzgGqSkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 标签原始数据的读取与分析\n",
        "test_dict = load_labels_to_memomery(labels_path, is_preview=False)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b3EMPqZGqSkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_labels_to_memomery(labels_path, is_preview=False):\n",
        "    if not os.path.exists(labels_path):\n",
        "        raise Exception(\"Labels path does not exist.\")\n",
        "\n",
        "    labels_dict = {}\n",
        "\n",
        "    for SET in os.listdir(os.path.join(labels_path)):\n",
        "        if SET[0] == \".\":  # 跳过隐藏文件\n",
        "            continue\n",
        "\n",
        "        SET_name = SET.split(\".\")[0]\n",
        "        if SET_name not in labels_dict:\n",
        "            labels_dict[SET_name] = []\n",
        "        read_from_file(os.path.join(labels_path, SET), labels_dict[SET_name])\n",
        "\n",
        "    if is_preview:\n",
        "        preview_labels(labels_dict)\n",
        "\n",
        "\n",
        "    labels_dict_with_mean = {}\n",
        "    for key in labels_dict:\n",
        "        labels_dict_with_mean[key] = []\n",
        "        for ls in labels_dict[key]:\n",
        "            if ls[0] is None:\n",
        "                labels_dict_with_mean[key].append(None)\n",
        "            else:\n",
        "                labels_dict_with_mean[key].append(np.mean(np.array(ls)))\n",
        "\n",
        "\n",
        "\n",
        "    return labels_dict_with_mean\n",
        "\n",
        "\n",
        "\n",
        "def read_from_file(file_path, ls):\n",
        "    fl = open(file_path)\n",
        "\n",
        "    while True:\n",
        "        line = fl.readline()\n",
        "\n",
        "        if line == \"\":\n",
        "            break\n",
        "\n",
        "        line_without_n = line.split(\"\\n\")[0]\n",
        "        if line_without_n == \"\":\n",
        "            continue\n",
        "\n",
        "        commit = line_without_n.split(\"#\")\n",
        "        if len(commit) > 1:  # 被标记\n",
        "            ls.append([None])  # 填None\n",
        "            continue\n",
        "\n",
        "        label_line = commit[0]\n",
        "        index_and_labels = label_line.split(\":\")\n",
        "        if len(index_and_labels) < 2:\n",
        "            continue\n",
        "\n",
        "        labels = index_and_labels[-1].split(\" \")\n",
        "\n",
        "        ls.append([])\n",
        "        for label in labels:\n",
        "            if label != \"\":\n",
        "                ls[-1].append(float(label))\n",
        "\n",
        "    fl.close()\n",
        "\n",
        "\n",
        "def get_bar(ls, step, start=None, title=None):\n",
        "    if start is None:\n",
        "        start = int(min(ls))\n",
        "    else:\n",
        "        if start > int(min(ls)):\n",
        "            print(\"指定的起点太大, 我还没写处理\")\n",
        "            exit(0)\n",
        "\n",
        "    end = int(max(ls)) + 1\n",
        "\n",
        "    names = [str(x) for x in range(start, end, step)]\n",
        "    width = 0.75\n",
        "    x_ticks = np.arange(len(names))\n",
        "    # x_ticks一定要用numpy, 因为要做矩阵操作\n",
        "\n",
        "    values = [0 for _ in range(len(names))]\n",
        "    for var in ls:\n",
        "        values[int((var - start) / step)] += 1\n",
        "\n",
        "    # fig, ax = plt.subplots()\n",
        "    # bar = plt.bar(names, values)\n",
        "    bar = plt.bar(x_ticks + width / 2, values, width)  # 默认居中, 所以加1/2\n",
        "    plt.xticks(x_ticks, names)  # 还原names\n",
        "    plt.bar_label(bar, label_type=\"edge\")\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def analysis(ls, step=5, title=None):\n",
        "    get_bar(ls, step, int(min(ls) / step) * step, title)\n",
        "\n",
        "\n",
        "def preview_labels(labels_dict, step=5):\n",
        "    all_data = [x\n",
        "                for key in labels_dict\n",
        "                for arr in labels_dict[key]\n",
        "                for x in arr\n",
        "                if x is not None]  # 我们将None异常算入\n",
        "    avg_data = [sum(arr) / len(arr)\n",
        "                for key in labels_dict\n",
        "                for arr in labels_dict[key]\n",
        "                if arr[0] is not None]\n",
        "    analysis(all_data, step, \"All Result Datas\")\n",
        "    analysis(avg_data, step, \"Average Result per Fruit Datas\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vMznL74YqSkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 读取数据并随labels转化为numpy\n",
        "test_dict = load_labels_to_memomery(labels_path, is_preview=False)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nPRQnCHgqSkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2.1 用于缓存和检查是否可以直接从缓存里拿"
      ],
      "metadata": {
        "id": "m-j0Kecz38aG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "98yek4xc370C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_pics_and_labels_to_numpy(datas_path, labels_dict):\n",
        "    if not os.path.exists(datas_path):\n",
        "        raise Exception(\"Datas path does not exist.\")\n",
        "\n",
        "    datas_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    for DIR in os.listdir(os.path.join(datas_path)):\n",
        "        if DIR[0] == \".\":  # 跳过隐藏文件\n",
        "            continue\n",
        "\n",
        "        SET, LABEL = get_info_set_and_label(os.path.join(datas_path, DIR))\n",
        "        # str, int SET = 1, 2, 3, 4... LABEL = 1, 2, 3, 4...\n",
        "        if labels_dict[SET][LABEL - 1] is None:\n",
        "            continue\n",
        "\n",
        "        single_data_list = []\n",
        "        for i in range(3):\n",
        "            for j in range(6):\n",
        "                video_name = str(i)\n",
        "                pic_name = str(j).zfill(10) + \".jpg\"\n",
        "                single_data_list.append(single_img_to_numpy(os.path.join(\n",
        "                    datas_path,\n",
        "                    DIR,\n",
        "                    video_name,\n",
        "                    pic_name)))\n",
        "\n",
        "        single_label_list = [labels_dict[SET][LABEL - 1]\n",
        "                             for _ in range(6)]\n",
        "\n",
        "        datas_list.append(np.array(single_data_list))\n",
        "        labels_list.append(np.array(single_label_list))\n",
        "\n",
        "    return np.array(datas_list), np.array(labels_list)\n",
        "\n",
        "\n",
        "def single_img_to_numpy(img_path):\n",
        "    trf = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    img = Image.open(img_path)\n",
        "    img = trf(img)\n",
        "    img = torch.unsqueeze(img, dim=0)\n",
        "    net = torchvision.models.resnet18(pretrained=True)\n",
        "    out = net(img)\n",
        "    single_line_numpy = out.detach().cpu().numpy().reshape(-1)\n",
        "    return single_line_numpy\n",
        "\n",
        "\n",
        "def get_info_set_and_label(DIR_path):\n",
        "    fl = open(os.path.join(DIR_path, \"info.txt\"))\n",
        "\n",
        "    content = fl.readline()\n",
        "    set_num = int(content.split(\"\\n\")[0].split(\":\")[-1])\n",
        "\n",
        "    fl.readline()  # 空读\n",
        "\n",
        "    content = fl.readline()\n",
        "    label_num = int(content.split(\"\\n\")[0].split(\":\")[-1])\n",
        "\n",
        "    fl.close()\n",
        "\n",
        "    return str(set_num), label_num"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TFr0BViWqSkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3 用于测试, 避免因小问题导致处理文件中间的耗时\n",
        "直接运行, 与错误会报错"
      ],
      "metadata": {
        "id": "pqvyQbHF1n0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pics_and_labels_to_numpy_test(datas_path, labels_dict):\n",
        "    if not os.path.exists(datas_path):\n",
        "        raise Exception(\"Datas path does not exist.\")\n",
        "    \n",
        "    for DIR in os.listdir(os.path.join(datas_path)):\n",
        "        if DIR[0] == \".\":  # 跳过隐藏文件\n",
        "            continue\n",
        "\n",
        "        SET, LABEL = get_info_set_and_label(os.path.join(datas_path, DIR))\n",
        "        # str, int SET = 1, 2, 3, 4... LABEL = 1, 2, 3, 4...\n",
        "        if labels_dict[SET][LABEL - 1] is None:\n",
        "            continue\n",
        "        for i in range(3):\n",
        "            for j in range(6):\n",
        "                video_name = str(i)\n",
        "                pic_name = str(j).zfill(10) + \".jpg\"\n",
        "                single_img_to_numpy_test(os.path.join(\n",
        "                    datas_path,\n",
        "                    DIR,\n",
        "                    video_name,\n",
        "                    pic_name))\n",
        "                \n",
        "def single_img_to_numpy_test(img_path):\n",
        "    if not os.path.exists(img_path):\n",
        "        print(img_path)\n",
        "        print(\"Oh shit\")\n",
        "        raise Exception(\"Image path does not exist.\")"
      ],
      "metadata": {
        "id": "OHkAHues1ndX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 load_from_drive本体"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xwtSrCRbqSkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_from_drive(project_path):\n",
        "    labels_dict = load_labels_to_memomery(os.path.join(project_path, \"label\"))\n",
        "    load_pics_and_labels_to_numpy_test(os.path.join(project_path, \"data\"), labels_dict)\n",
        "    return load_pics_and_labels_to_numpy(os.path.join(project_path, \"data\"), labels_dict)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hyeIkpOvqSkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 得到数据集与标签集的numpy元组\n",
        "\n",
        "```\n",
        "dataset = train_data(r'E:\\peach\\data').reshape(-1, 18, 1000)  # reshape改为一个三维数组（-1是模糊控制，行未知，18列，1000页）\n",
        "print(dataset.shape)\n",
        "labelset = np.array(get_label(r'E:\\peach\\油桃硬度.xlsx'))\n",
        "print(labelset.shape)\n",
        "```\n",
        "\n",
        "```\n",
        "dataset, labelset = datas_and_labels\n",
        "```"
      ],
      "metadata": {
        "id": "smkXfat7sU6V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "datas_and_labels = load_from_drive(PROJECT_PATH)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "bZaAwKlsqSkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 代码 "
      ],
      "metadata": {
        "id": "K0_XZ_zQtAoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(datas_and_labels[0].shape)\n",
        "print(datas_and_labels[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF4WvybvtS6P",
        "outputId": "0d7f47e9-9c25-4b9c-cc39-50cd586f98e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(101, 18, 1000)\n",
            "(101, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 三通道LSTM模型类"
      ],
      "metadata": {
        "id": "L5KK4BvWuMc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Lstm_model(Module):\n",
        "    def __init__(self):  # 初始化\n",
        "        super(Lstm_model, self).__init__()\n",
        "        self.lstm1 = LSTM(input_size=1000, hidden_size=512,\n",
        "                          num_layers=1, batch_first=True)\n",
        "        self.lstm2 = LSTM(input_size=1000, hidden_size=512,\n",
        "                          num_layers=1, batch_first=True)\n",
        "        self.lstm3 = LSTM(input_size=1000, hidden_size=512,\n",
        "                          num_layers=1, batch_first=True)\n",
        "        self.linear1 = Linear(in_features=512, out_features=1)\n",
        "        self.linear2 = Linear(in_features=512, out_features=1)\n",
        "        self.linear3 = Linear(in_features=512, out_features=1)\n",
        "        self.linear = Linear(in_features=18, out_features=1)\n",
        "        self.active = torch.nn.LeakyReLU()\n",
        "        self.bn = BatchNorm1d(num_features=18)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = x.reshape(1, -1, 1000)\n",
        "        # print(x.shape)\n",
        "        x01 = x[0, 0:6, :]\n",
        "        x02 = x[0, 6:12, :]\n",
        "        x03 = x[0, 12:18, :]\n",
        "        x01 = x01.reshape(1, -1, 1000)\n",
        "        x02 = x02.reshape(1, -1, 1000)\n",
        "        x03 = x03.reshape(1, -1, 1000)\n",
        "        x1, _ = self.lstm1(x01, hidden)\n",
        "        x2, _ = self.lstm2(x02, hidden)\n",
        "        x3, _ = self.lstm3(x03, hidden)\n",
        "        # print(x1.shape)\n",
        "        # print(x2.shape)\n",
        "        # print(x3.shape)\n",
        "        x1 = self.linear1(x1)\n",
        "        x1 = self.active(x1)\n",
        "        x2 = self.linear2(x2)\n",
        "        x2 = self.active(x2)\n",
        "        x3 = self.linear3(x3)\n",
        "        x3 = self.active(x3)\n",
        "        # print(x1.shape)\n",
        "        # print(x2.shape)\n",
        "        # print(x3.shape)\n",
        "        x = torch.cat((x1, x2, x3), dim=1).reshape(-1)\n",
        "        # print(x.shape)\n",
        "        x = self.linear(x)\n",
        "        # print(x.shape)\n",
        "        return x"
      ],
      "metadata": {
        "id": "a9bekYte9TUr",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 基本参数初始化"
      ],
      "metadata": {
        "id": "7gn9Vm-puw2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0')\n",
        "model = Lstm_model().to(device)\n",
        "\n",
        "dataset, labelset = datas_and_labels\n",
        "\n",
        "train_X, valid_X, train_Y, valid_Y = train_test_split(dataset, labelset,\n",
        "                                                      test_size=0.2, random_state=1)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  # 学习率\n",
        "criterion = torch.nn.MSELoss()\n",
        "train_X, train_Y = torch.from_numpy(train_X).float(), torch.from_numpy(train_Y).float()\n",
        "train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=1, shuffle=True)\n",
        "valid_X, valid_Y = torch.from_numpy(valid_X).float(), torch.from_numpy(valid_Y).float()\n",
        "valid_loader = DataLoader(TensorDataset(valid_X, valid_Y), batch_size=1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "grjWmd5f9MhA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 训练与评估"
      ],
      "metadata": {
        "id": "OfOdocRhu9zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch_num):\n",
        "    model.train()\n",
        "    running_loss = []\n",
        "    for index, (data, label) in enumerate(train_loader):\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # label = torch.unsqueeze(label, dim=1)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss.append(loss.item())\n",
        "    train_loss = np.mean(running_loss)\n",
        "    model.eval()\n",
        "\n",
        "    val_running_loss = []\n",
        "    for index, (data, label) in enumerate(valid_loader):\n",
        "        data, label = data.to(device), label.to(\n",
        "            device)  # print(index)# print(\"label.shape\", label.shape)# print(\"label\", label)# print(\"data.shape\", data.shape)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # label = torch.unsqueeze(label, dim=1)\n",
        "        # print(\"output.shape:\", output.shape)# print(\"output:\", output)\n",
        "        loss = criterion(output, label)  # print('loss:', loss)\n",
        "        val_running_loss.append(loss.item())\n",
        "    val_loss = np.mean(val_running_loss)\n",
        "    print(\"epoch={}, train_loss:{}, val_loss:{}\".format(epoch_num, train_loss, val_loss))\n",
        "    return train_loss, val_loss  # 用于hook\n",
        "\n",
        "\n",
        "def evl():\n",
        "    # 预测过程\n",
        "    model.eval()\n",
        "    # hidden_predict = None\n",
        "    trian_error_list = []\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        data_X = data.to(device)\n",
        "        # pred_X = model(data_X, hidden_predict)\n",
        "        pred_X = model(data_X)\n",
        "        cur_pred = pred_X.detach().cpu().numpy()\n",
        "        cur_label = label.detach().cpu().numpy()\n",
        "        # cur_label = torch.unsqueeze(label, dim=-1).detach().cpu().numpy()\n",
        "        cur_erro = np.mean(np.abs(cur_pred - cur_label))\n",
        "        trian_error_list.append(cur_erro)\n",
        "    train_error = np.mean(trian_error_list, axis=0)\n",
        "\n",
        "    val_error_list = []\n",
        "    pre_list = []\n",
        "    lab_list = []\n",
        "    for data, label in valid_loader:\n",
        "        data_X = data.to(device)\n",
        "        pred_X = model(data_X)\n",
        "        cur_pred = pred_X.detach().cpu().numpy().reshape(-1)\n",
        "        cur_label = label.detach().cpu().numpy().reshape(-1)\n",
        "        cur_erro = np.mean(np.abs(cur_pred - cur_label))\n",
        "        val_error_list.append(cur_erro)\n",
        "        pre_list.append(cur_pred)\n",
        "        lab_list.append(cur_label)\n",
        "    val_error = np.mean(val_error_list, axis=0)\n",
        "    np.savetxt(os.path.join(PROJECT_PATH, 'pre.txt'),\n",
        "                            np.array(pre_list).reshape(-1, 1),\n",
        "                            fmt='%0.2f')\n",
        "    np.savetxt(os.path.join(PROJECT_PATH, 'lab.txt'),\n",
        "               np.array(lab_list).reshape(-1, 1), \n",
        "               fmt='%0.2f')\n",
        "    # np.savetxt(r'E:\\kiwi2\\merge_kiwi\\pre.txt', np.array(pre_list))\n",
        "    # np.savetxt(r'E:\\kiwi2\\merge_kiwi\\lab.txt', np.array(lab_list))\n",
        "    print(\"train_error:{}, val_error:{}\".format(train_error, val_error))\n",
        "    return train_error, val_error"
      ],
      "metadata": {
        "id": "oK2JIFsIvDSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 可视化"
      ],
      "metadata": {
        "id": "euQnfwDG21Tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataViwer:\n",
        "    def __init__(self, period=None, title=None):\n",
        "        self.cnt = 0\n",
        "        self.datas = []\n",
        "        self.period = period\n",
        "        self.title = title\n",
        "\n",
        "    def add_data(self, new_data, new_period=None):\n",
        "        self.cnt += 1\n",
        "        self.datas.append(new_data)\n",
        "\n",
        "        if new_period is not None:\n",
        "            self.period = new_period\n",
        "\n",
        "        if self.period is None:\n",
        "            return\n",
        "\n",
        "        if self.cnt != 0 and self.cnt % self.period == 0:\n",
        "            self.show()\n",
        "\n",
        "    def show(self):\n",
        "        plt.cla()\n",
        "        plt.plot(np.arange(len(self.datas)), np.array(self.datas))\n",
        "        if self.title is not None:\n",
        "            plt.title(self.title)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "zB_4JIUk26HQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. main函数"
      ],
      "metadata": {
        "id": "eZbYy5Ipvu0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errormin = 0.9\n",
        "\n",
        "tl = DataViwer(20, 'Loss/train')\n",
        "vl = DataViwer(20, 'Loss/val')\n",
        "te = DataViwer(20, 'Error/train')\n",
        "ve = DataViwer(20, 'Error/val')\n",
        "\n",
        "\n",
        "for epoch in range(1, 2000):\n",
        "    print('epoch = ', epoch)\n",
        "    train_loss, val_loss = train(epoch)\n",
        "    train_error, val_error = evl()\n",
        "\n",
        "    #writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "    #writer.add_scalar('Loss/val', val_loss, epoch)\n",
        "    #writer.add_scalar('Error/train', train_error, epoch)\n",
        "    #writer.add_scalar('Error/val', val_error, epoch)\n",
        "\n",
        "    tl.add_data(train_loss)\n",
        "    vl.add_data(val_loss)\n",
        "    te.add_data(train_error)\n",
        "    ve.add_data(val_error)\n",
        "\n",
        "    error = val_error\n",
        "\n",
        "\n",
        "    if error < errormin:\n",
        "        errormin = error\n",
        "        # time.sleep(10)\n",
        "        torch.save(model.state_dict(), \n",
        "                   os.path.join(PROJECT_PATH, \"weight\", 'kiwi_new.pth'))\n",
        "    print('-' * 80)\n",
        "\n",
        "#print(\"end\")\n",
        "\n",
        "tl.show()\n",
        "vl.show()\n",
        "te.show()\n",
        "ve.show()\n",
        "\n",
        "\n",
        "print(\"finally_average_error:\", errormin)\n",
        "#writer.close()"
      ],
      "metadata": {
        "id": "XI03xVIHvuLe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}